{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMU Advanced NLP 2022 : Introduction to NLP \n",
    "\n",
    "This notebook contains example codes from [anlp-codes](https://github.com/neubig/anlp-code/blob/main/01-rulebasedclassifier/rulebasedclassifier.ipynb). After downloading the original rule-based model, I next play around and try several simple modifications. First, I start with an analysis on data and visualize several properties to better understand it. Then in Methods section, I run the baseline model and my modifications to it. The notebook only contains simple rule-based model, not fancy deep learning models. \n",
    "\n",
    "\n",
    "## Section 1: Understanding the data \n",
    "\n",
    "\n",
    "The data is from [anlp-code/data](https://github.com/neubig/anlp-code/tree/main/data/sst-sentiment-text-threeclass).  Let's explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is from anlp-codes. \n",
    "def read_XY_data(filename):\n",
    "    X_data = []\n",
    "    Y_data = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            label, text = line.strip().split(' ||| ')\n",
    "            X_data.append(text)\n",
    "            Y_data.append(int(label))\n",
    "    return X_data, Y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, I only look the training and dev data. Test data is secret, we can't explore it. \n",
    "\n",
    "For better visualization and exploration, I will transform these two sets into pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = read_XY_data('data/sst-sentiment-text-threeclass/train.txt')\n",
    "X_test, Y_test = read_XY_data('data/sst-sentiment-text-threeclass/dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Singer\\/composer Bryan Adams contributes a sle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You 'd think by now America would have had eno...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yet the act is still charming here .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Label\n",
       "0  The Rock is destined to be the 21st Century 's...      1\n",
       "1  The gorgeously elaborate continuation of `` Th...      1\n",
       "2  Singer\\/composer Bryan Adams contributes a sle...      1\n",
       "3  You 'd think by now America would have had eno...      0\n",
       "4               Yet the act is still charming here .      1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(zip(X_train + X_test, Y_train + Y_test)),\n",
    "               columns =['Review', 'Label'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9645 examples with 2 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"There are %d examples with %d columns\"%(df.shape[0], df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I try to answer several questions related to the training set. \n",
    "\n",
    "1. What is the distribution of the classes? \n",
    "2. What is the length (nbr of words) of the reviews by each classes? \n",
    "3. What is the most frequent adjectives in the reviews by the classes?\n",
    "4. What is the most frequent names in the reviews by the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. What is the distribution of the classes?\n",
    "label_counts = df.Label.value_counts()\n",
    "colors = sns.color_palette('pastel')[0:3]\n",
    "\n",
    "#create pie chart\n",
    "plt.pie(label_counts, labels = [\"1\",\"-1\",\"0\"], colors = colors, autopct='%.0f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the classes in the set is not homogeneous. The reviews from neutral class (0) is fewer than others(1,-1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Singer\\/composer Bryan Adams contributes a sle...</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You 'd think by now America would have had eno...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yet the act is still charming here .</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Label  word_count\n",
       "0  The Rock is destined to be the 21st Century 's...      1          36\n",
       "1  The gorgeously elaborate continuation of `` Th...      1          37\n",
       "2  Singer\\/composer Bryan Adams contributes a sle...      1          39\n",
       "3  You 'd think by now America would have had eno...      0          19\n",
       "4               Yet the act is still charming here .      1           8"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. What is the length of the reviews by each classes? \n",
    "# get the number of words in each review \n",
    "word_count = df.Review.str.split().str.len()\n",
    "df['word_count'] = word_count\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now get the average number of word count by classes \n",
    "average_word_nbr = df.groupby(['Label'])['word_count'].mean()\n",
    " \n",
    "# creating the bar plot\n",
    "plt.bar([\"-1\",\"0\",\"1\"], average_word_nbr, color=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average number of words in the reviews are very close for each class. \n",
    "\n",
    "For the next question, about finding the adjectives, I use nltk library to first tokenize the reviews than to tag them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/mignon/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. What is the most frequent adjectives in the reviews by the classes?\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('different', 'JJ'),\n",
       " ('is', 'VBZ'),\n",
       " ('not', 'RB'),\n",
       " ('coming', 'VBG')]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "text = word_tokenize(\"And now for something completely different is not coming\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>[(the, DT), (rock, NN), (is, VBZ), (destined, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>[(the, DT), (gorgeously, RB), (elaborate, JJ),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Singer\\/composer Bryan Adams contributes a sle...</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>[(singer\\/composer, NN), (bryan, NN), (adams, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You 'd think by now America would have had eno...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>[(you, PRP), ('d, MD), (think, VB), (by, IN), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yet the act is still charming here .</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>[(yet, RB), (the, DT), (act, NN), (is, VBZ), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Label  word_count  \\\n",
       "0  The Rock is destined to be the 21st Century 's...      1          36   \n",
       "1  The gorgeously elaborate continuation of `` Th...      1          37   \n",
       "2  Singer\\/composer Bryan Adams contributes a sle...      1          39   \n",
       "3  You 'd think by now America would have had eno...      0          19   \n",
       "4               Yet the act is still charming here .      1           8   \n",
       "\n",
       "                                                tags  \n",
       "0  [(the, DT), (rock, NN), (is, VBZ), (destined, ...  \n",
       "1  [(the, DT), (gorgeously, RB), (elaborate, JJ),...  \n",
       "2  [(singer\\/composer, NN), (bryan, NN), (adams, ...  \n",
       "3  [(you, PRP), ('d, MD), (think, VB), (by, IN), ...  \n",
       "4  [(yet, RB), (the, DT), (act, NN), (is, VBZ), (...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tags'] = df.Review.apply(lambda x: nltk.pos_tag(word_tokenize(x.lower())))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The keys are the index numbers \n",
      "Each example contains:  dict_keys(['Review', 'Label', 'word_count', 'tags'])\n"
     ]
    }
   ],
   "source": [
    "# transform dataframe into a dictionary \n",
    "df_dict = df.to_dict('index')\n",
    "print(\"The keys are the index numbers \")\n",
    "print(\"Each example contains: \", df_dict[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mignon/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tags in classes (0,1,-1) (1853,4054,3738)\n"
     ]
    }
   ],
   "source": [
    "# collect tags of each class \n",
    "class_tags = {0:[],1:[],-1:[]}\n",
    "for k,v in df_dict.items():\n",
    "    class_tags[v[\"Label\"]].append(v['tags'])\n",
    "print(\"Number of tags in classes (0,1,-1) (%d,%d,%d)\"%(len(class_tags[0]),len(class_tags[1]),len(class_tags[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten each list to get the counts of each word \n",
    "# filter to choose only adjactives \n",
    "# count the tag-word pairs in each class\n",
    "adjectives = [\"JJ\",\"JJS\",\"JJR\"]\n",
    "class_tags[0] = Counter([x for s in class_tags[0] for x in s if (x[1] in adjectives and not(x[0] in stop_words))])\n",
    "class_tags[1] = Counter([x for s in class_tags[1] for x in s if x[1] in adjectives and not(x[0] in stop_words)])\n",
    "class_tags[-1] = Counter([x for s in class_tags[-1] for x in s if x[1] in adjectives and  not(x[0] in stop_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common adjectives in positive class : \n",
      "[(('good', 'JJ'), 154), (('funny', 'JJ'), 119), (('best', 'JJS'), 117), (('little', 'JJ'), 90), (('new', 'JJ'), 80), (('great', 'JJ'), 75), (('many', 'JJ'), 59), (('big', 'JJ'), 58), (('human', 'JJ'), 57), (('real', 'JJ'), 57)]\n",
      "Most common adjectives in negative class : \n",
      "[(('bad', 'JJ'), 152), (('much', 'JJ'), 93), (('good', 'JJ'), 91), (('little', 'JJ'), 89), (('new', 'JJ'), 60), (('many', 'JJ'), 57), (('funny', 'JJ'), 51), (('big', 'JJ'), 48), (('hard', 'JJ'), 46), (('better', 'JJR'), 43)]\n",
      "Most common adjectives in neutral class : \n",
      "[(('good', 'JJ'), 58), (('much', 'JJ'), 39), (('little', 'JJ'), 38), (('funny', 'JJ'), 36), (('many', 'JJ'), 33), (('new', 'JJ'), 30), (('best', 'JJS'), 28), (('big', 'JJ'), 25), (('old', 'JJ'), 22), (('first', 'JJ'), 21)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Most common adjectives in positive class : \")\n",
    "print(class_tags[1].most_common(10))\n",
    "print(\"Most common adjectives in negative class : \")\n",
    "print(class_tags[-1].most_common(10))\n",
    "print(\"Most common adjectives in neutral class : \")\n",
    "print(class_tags[0].most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't see much differences just looking the adjective. The reason may be the negation. I can now check the verbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tags in classes (0,1,-1) (1853,4054,3738)\n"
     ]
    }
   ],
   "source": [
    "# collect tags of each class \n",
    "class_tags = {0:[],1:[],-1:[]}\n",
    "for k,v in df_dict.items():\n",
    "    class_tags[v[\"Label\"]].append(v['tags'])\n",
    "print(\"Number of tags in classes (0,1,-1) (%d,%d,%d)\"%(len(class_tags[0]),len(class_tags[1]),len(class_tags[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten each list to get the counts of each word \n",
    "# filter to choose only verbs \n",
    "# count the tag-word pairs in each class\n",
    "verbs = [\"VB\"]\n",
    "class_tags[0] = Counter([x for s in class_tags[0] for x in s if x[1].startswith(\"VB\") and not(x[0] in stop_words)])\n",
    "class_tags[1] = Counter([x for s in class_tags[1] for x in s if x[1].startswith(\"VB\") and not(x[0] in stop_words)])\n",
    "class_tags[-1] = Counter([x for s in class_tags[-1] for x in s if x[1].startswith(\"VB\") and not(x[0] in stop_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common adjectives in positive class : \n",
      "[((\"'s\", 'VBZ'), 562), (('makes', 'VBZ'), 105), (('make', 'VB'), 60), ((\"'re\", 'VBP'), 50), (('see', 'VB'), 50), (('seen', 'VBN'), 44), (('gives', 'VBZ'), 43), ((\"'ve\", 'VBP'), 42), (('make', 'VBP'), 40), (('takes', 'VBZ'), 39), (('keep', 'VB'), 39), (('made', 'VBN'), 38), (('works', 'VBZ'), 37), (('moving', 'VBG'), 37), (('take', 'VB'), 36), (('watch', 'VB'), 33), (('watching', 'VBG'), 33), (('seems', 'VBZ'), 33), (('get', 'VB'), 32), (('gets', 'VBZ'), 31)]\n",
      "Most common adjectives in negative class : \n",
      "[((\"'s\", 'VBZ'), 553), (('make', 'VB'), 73), (('seems', 'VBZ'), 67), (('makes', 'VBZ'), 63), ((\"'re\", 'VBP'), 57), (('comes', 'VBZ'), 50), ((\"'ve\", 'VBP'), 46), (('watching', 'VBG'), 45), (('made', 'VBN'), 43), (('get', 'VB'), 42), (('see', 'VB'), 40), (('going', 'VBG'), 33), (('feel', 'VB'), 31), (('gets', 'VBZ'), 31), (('seem', 'VBP'), 31), (('trying', 'VBG'), 30), (('goes', 'VBZ'), 29), (('takes', 'VBZ'), 29), (('find', 'VB'), 29), (('go', 'VB'), 28)]\n",
      "Most common adjectives in neutral class : \n",
      "[((\"'s\", 'VBZ'), 274), (('make', 'VB'), 36), (('made', 'VBN'), 35), (('makes', 'VBZ'), 33), ((\"'re\", 'VBP'), 30), (('see', 'VB'), 24), (('get', 'VB'), 22), (('comes', 'VBZ'), 20), (('gets', 'VBZ'), 20), (('find', 'VB'), 18), (('seen', 'VBN'), 18), (('go', 'VB'), 18), ((\"'ve\", 'VBP'), 15), (('look', 'VB'), 15), (('takes', 'VBZ'), 13), (('watch', 'VB'), 13), (('seems', 'VBZ'), 13), (('want', 'VB'), 13), (('want', 'VBP'), 12), (('give', 'VB'), 12)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Most common adjectives in positive class : \")\n",
    "print(class_tags[1].most_common(20))\n",
    "print(\"Most common adjectives in negative class : \")\n",
    "print(class_tags[-1].most_common(20))\n",
    "print(\"Most common adjectives in neutral class : \")\n",
    "print(class_tags[0].most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Rule-based Sentiment Classifier\n",
    "\n",
    "This is a notebook for [CMU CS11-711 Advanced NLP](http://phontron.com/class/anlp2021/), in which you can attempt to build a rule-based sentiment classifier. It will take in a text `X` and return a `label` of \"1\" if the sentiment of the text is positive, \"-1\" if the sentiment of the text is negative, and \"0\" if the sentiment of the text is neutral. You can test the accuracy of your classifier on the [Stanford Sentiment Treebank](http://nlp.stanford.edu/sentiment/index.html) by running the notebook all the way to end.\n",
    "\n",
    "The only thing that you should change in this notebook is the following cell which contains two important elements. The first is `extract_features(X)`, which will extract a dictionary of (named) feature values from the text. You should create this by hand, and a simple example is shown for you. The second is `feature_weights`, a dictionary which will assign a weight to each extracted feature.\n",
    "\n",
    "The final way the classifier decides whether to assign a positive, negative, or neutral label is by calculating the dot product `feature_weights * extract_features(X)`, and if the value is greater than zero, return 1, less than zero return -1, and if exactly zero return 0.\n",
    "\n",
    "Let's have some fun trying to design a classifier 😁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(X):\n",
    "    features = {}\n",
    "    X_split = X.split(' ')\n",
    "    \n",
    "    # Count the number of \"good words\" and \"bad words\" in the text\n",
    "    good_words = ['love', 'good']\n",
    "    bad_words = ['hate', 'bad']\n",
    "    for x in good_words: \n",
    "        if x in X: \n",
    "            features['good_word_count'] = features.get('good_word_count', 0) + 1\n",
    "    for x in bad_words: \n",
    "        if x in X: \n",
    "            features['bad_word_count'] = features.get('good_word_count', 0) + 1\n",
    "\n",
    "    # The \"bias\" value is always one, to allow us to assign a \"default\" score to the text\n",
    "    features['bias'] = 1\n",
    "    \n",
    "    return features\n",
    "\n",
    "feature_weights = {'good_word_count': 1.0, 'bad_word_count': -1.0, 'bias': 0.5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reading\n",
    "\n",
    "Read in the data from the training and dev (or finally test) sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_XY_data(filename):\n",
    "    X_data = []\n",
    "    Y_data = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            label, text = line.strip().split(' ||| ')\n",
    "            X_data.append(text)\n",
    "            Y_data.append(int(label))\n",
    "    return X_data, Y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = read_XY_data('data/sst-sentiment-text-threeclass/train.txt')\n",
    "X_test, Y_test = read_XY_data('data/sst-sentiment-text-threeclass/dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal .\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Classifier and Calculate Accuracy\n",
    "\n",
    "Run the classifier over the training and dev (test) sets and calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifier(X):\n",
    "    score = 0\n",
    "    for feat_name, feat_value in extract_features(X).items():\n",
    "        score = score + feat_value * feature_weights.get(feat_name, 0)\n",
    "    if score > 0:\n",
    "        return 1\n",
    "    elif score < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(X_data, Y_data):\n",
    "    total_number = 0\n",
    "    correct_number = 0\n",
    "    for X, Y in zip(X_data, Y_data):\n",
    "        Y_pred = run_classifier(X)\n",
    "        total_number += 1\n",
    "        if Y == Y_pred:\n",
    "            correct_number += 1\n",
    "    return correct_number / float(total_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.43551029962546817\n",
      "Dev/test accuracy: 0.4196185286103542\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calculate_accuracy(X_train, Y_train)\n",
    "test_accuracy = calculate_accuracy(X_test, Y_test)\n",
    "print(f'Train accuracy: {train_accuracy}')\n",
    "print(f'Dev/test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "An important part of improving any system is figuring out where it goes wrong. The following two functions allow you to randomly observe some mistaken examples, which may help you improve the classifier. Feel free to write more sophisticated methods for error analysis as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def find_errors(X_data, Y_data):\n",
    "    error_ids = []\n",
    "    Y_preds = []\n",
    "    for i, (X, Y) in enumerate(zip(X_data, Y_data)):\n",
    "        Y_preds.append(run_classifier(X))\n",
    "        if Y != Y_preds[-1]:\n",
    "            error_ids.append(i)\n",
    "    for _ in range(5):\n",
    "        my_id = random.choice(error_ids)\n",
    "        X, Y, Y_pred = X_data[my_id], Y_data[my_id], Y_preds[my_id]\n",
    "        print(f'{X}\\ntrue label: {Y}\\npredicted label: {Y_pred}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every visual joke is milked , every set-up obvious and lengthy , every punchline predictable .\n",
      "true label: -1\n",
      "predicted label: 1\n",
      "\n",
      "But here 's a movie about it anyway .\n",
      "true label: -1\n",
      "predicted label: 1\n",
      "\n",
      "Dark and disturbing , yet compelling to watch .\n",
      "true label: 0\n",
      "predicted label: 1\n",
      "\n",
      "Lucky Break is perfectly inoffensive and harmless , but it 's also drab and inert .\n",
      "true label: 0\n",
      "predicted label: 1\n",
      "\n",
      "Master of Disguise runs for only 71 minutes and feels like three hours .\n",
      "true label: -1\n",
      "predicted label: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_errors(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to improve the results? \n",
    "\n",
    "* I can get a dictionary from training data to assign as good and bad words. \n",
    "* Using n-grams to score the negative, positive words \n",
    "* Using stemming \n",
    "\n",
    "\n",
    "\n",
    "I have already examined the data and the vocabulary. I can first expand the bad and good vocabulary in the feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(X):\n",
    "    features = {}\n",
    "    X_split = X.split(' ')\n",
    "    \n",
    "    # Count the number of \"good words\" and \"bad words\" in the text\n",
    "    good_words = ['love','entertaining', 'real', 'new', 'great', 'best', 'funny', 'good']\n",
    "    bad_words = ['dull', 'worst', 'hard', 'bad']\n",
    "    for x in good_words: \n",
    "        if x in X: \n",
    "            features['good_word_count'] = features.get('good_word_count', 0) + 1\n",
    "    for x in bad_words: \n",
    "        if x in X: \n",
    "            features['bad_word_count'] = features.get('good_word_count', 0) + 1\n",
    "\n",
    "    # The \"bias\" value is always one, to allow us to assign a \"default\" score to the text\n",
    "    features['bias'] = 1\n",
    "    \n",
    "    return features\n",
    "\n",
    "feature_weights = {'good_word_count': 1.0, 'bad_word_count': -1.0, 'bias': 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.44592696629213485\n",
      "Dev/test accuracy: 0.4305177111716621\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calculate_accuracy(X_train, Y_train)\n",
    "test_accuracy = calculate_accuracy(X_test, Y_test)\n",
    "print(f'Train accuracy: {train_accuracy}')\n",
    "print(f'Dev/test accuracy: {test_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
