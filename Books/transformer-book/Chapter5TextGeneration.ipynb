{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM8yqrvnRZgVdh3/mOBGSES"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets"],"metadata":{"id":"vwW5tgU4xWOh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Chapter 5: Text Generation \n","\n","\n","**Decoding** is the process of selecting the next token from the output distribution of the model.  When a prompt is given to LM model, it predicts a token for the sequence, and use the predicted token again in the next time step to continue on until it predicts a special end token. The goal of the decoding is to search for the most probable token over the vocabulary. Since searching over whole vocabulary is not applicable, we rely on the approximations.  \n","\n","\n","\n","* Autoregressive/ Casual LMs \n","\n","* Pre-training of GPT and BERT \n","\n","## Greedy Search Decoding \n","\n","The simplest method is to greedily select the token with the highest probability at each time step. \n","\n","\n","\n"],"metadata":{"id":"EDngrJLauxUv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DIDgoOZ0q6M4"},"outputs":[],"source":["# Load the model \n","import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","# model_name = \"gpt2-xl\"\n","model_name = \"gpt2\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"]},{"cell_type":"markdown","source":["**Exercise:** Try to implement the greedy algorithm using the loaded model. \n","\n","The decoding step runs 8 timestep. At each timestep, \n","1. Pick out the model's logits for the last token in the prompt and wrap them with a softmax to get a probability distribution. \n","2. Pick the next token with the highest one and add it to the input "],"metadata":{"id":"zS36Dh61xlZm"}},{"cell_type":"code","source":["# Solution \n","import pandas as pd\n","\n","input_txt = \"Transformers are the\"\n","input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n","iterations = []\n","n_steps = 8\n","choices_per_step = 5\n","\n","with torch.no_grad():\n","    for _ in range(n_steps):\n","        iteration = dict()\n","        iteration[\"Input\"] = tokenizer.decode(input_ids[0])\n","        output = model(input_ids=input_ids)\n","        # Select logits of the first batch and the last token and apply softmax\n","        next_token_logits = output.logits[0, -1, :]\n","        next_token_probs = torch.softmax(next_token_logits, dim=-1)\n","        sorted_ids = torch.argsort(next_token_probs, dim=-1, descending=True)\n","        # Store tokens with highest probabilities\n","        for choice_idx in range(choices_per_step):\n","            token_id = sorted_ids[choice_idx]\n","            token_prob = next_token_probs[token_id].cpu().numpy()\n","            token_choice = (\n","                f\"{tokenizer.decode(token_id)} ({100 * token_prob:.2f}%)\"\n","            )\n","            iteration[f\"Choice {choice_idx+1}\"] = token_choice\n","        # Append predicted next token to input\n","        input_ids = torch.cat([input_ids, sorted_ids[None, 0, None]], dim=-1)\n","        iterations.append(iteration)\n","\n","pd.DataFrame(iterations)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":494},"id":"vZUB6rNdxkvB","executionInfo":{"status":"ok","timestamp":1675806109371,"user_tz":480,"elapsed":517,"user":{"displayName":"Merve Unlu Menevse","userId":"07208082643217875039"}},"outputId":"9898d5bb-f35c-4e26-ed0a-5ea0096569aa"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               Input           Choice 1  \\\n","0                               Transformers are the       most (9.76%)   \n","1                          Transformers are the most    common (22.90%)   \n","2                   Transformers are the most common      type (15.06%)   \n","3              Transformers are the most common type        of (83.13%)   \n","4           Transformers are the most common type of   particle (1.55%)   \n","5  Transformers are the most common type of particle         . (14.26%)   \n","6  Transformers are the most common type of parti...      They (17.48%)   \n","7  Transformers are the most common type of parti...       are (38.78%)   \n","\n","            Choice 2            Choice 3          Choice 4  \\\n","0       same (2.94%)        only (2.87%)      best (2.38%)   \n","1   powerful (6.88%)   important (6.32%)   popular (3.95%)   \n","2      types (3.31%)        form (1.91%)       way (1.89%)   \n","3         in (3.16%)           . (1.92%)         , (1.63%)   \n","4     object (1.02%)       light (0.71%)    energy (0.67%)   \n","5        in (11.57%)       that (10.19%)         , (9.57%)   \n","6        \\n (15.19%)         The (7.06%)     These (3.09%)   \n","7       have (8.14%)         can (7.98%)       're (5.04%)   \n","\n","               Choice 5  \n","0         first (1.77%)  \n","1      commonly (2.14%)  \n","2           and (1.49%)  \n","3           for (0.88%)  \n","4       objects (0.66%)  \n","5   accelerator (5.81%)  \n","6            In (3.07%)  \n","7       consist (1.57%)  "],"text/html":["\n","  <div id=\"df-cbeaca54-650e-4f9a-bf18-205ccfb329b1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Input</th>\n","      <th>Choice 1</th>\n","      <th>Choice 2</th>\n","      <th>Choice 3</th>\n","      <th>Choice 4</th>\n","      <th>Choice 5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Transformers are the</td>\n","      <td>most (9.76%)</td>\n","      <td>same (2.94%)</td>\n","      <td>only (2.87%)</td>\n","      <td>best (2.38%)</td>\n","      <td>first (1.77%)</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Transformers are the most</td>\n","      <td>common (22.90%)</td>\n","      <td>powerful (6.88%)</td>\n","      <td>important (6.32%)</td>\n","      <td>popular (3.95%)</td>\n","      <td>commonly (2.14%)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Transformers are the most common</td>\n","      <td>type (15.06%)</td>\n","      <td>types (3.31%)</td>\n","      <td>form (1.91%)</td>\n","      <td>way (1.89%)</td>\n","      <td>and (1.49%)</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Transformers are the most common type</td>\n","      <td>of (83.13%)</td>\n","      <td>in (3.16%)</td>\n","      <td>. (1.92%)</td>\n","      <td>, (1.63%)</td>\n","      <td>for (0.88%)</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Transformers are the most common type of</td>\n","      <td>particle (1.55%)</td>\n","      <td>object (1.02%)</td>\n","      <td>light (0.71%)</td>\n","      <td>energy (0.67%)</td>\n","      <td>objects (0.66%)</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Transformers are the most common type of particle</td>\n","      <td>. (14.26%)</td>\n","      <td>in (11.57%)</td>\n","      <td>that (10.19%)</td>\n","      <td>, (9.57%)</td>\n","      <td>accelerator (5.81%)</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Transformers are the most common type of parti...</td>\n","      <td>They (17.48%)</td>\n","      <td>\\n (15.19%)</td>\n","      <td>The (7.06%)</td>\n","      <td>These (3.09%)</td>\n","      <td>In (3.07%)</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Transformers are the most common type of parti...</td>\n","      <td>are (38.78%)</td>\n","      <td>have (8.14%)</td>\n","      <td>can (7.98%)</td>\n","      <td>'re (5.04%)</td>\n","      <td>consist (1.57%)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbeaca54-650e-4f9a-bf18-205ccfb329b1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cbeaca54-650e-4f9a-bf18-205ccfb329b1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cbeaca54-650e-4f9a-bf18-205ccfb329b1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["# Using generate function from the library \n","input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n","output = model.generate(input_ids, max_new_tokens=n_steps, do_sample=False)\n","print(tokenizer.decode(output[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Onyo0LF60nte","executionInfo":{"status":"ok","timestamp":1675806200095,"user_tz":480,"elapsed":425,"user":{"displayName":"Merve Unlu Menevse","userId":"07208082643217875039"}},"outputId":"09a2051d-82c7-480d-d71f-4af7eb3cf103"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Transformers are the most common type of particle. They are\n"]}]},{"cell_type":"code","source":["# Trying to generate unicorn story from OpenAI\n","max_length = 128\n","input_txt = \"\"\"In a shocking finding, scientist discovered \\\n","a herd of unicorns living in a remote, previously unexplored \\\n","valley, in the Andes Mountains. Even more surprising to the \\\n","researchers was the fact that the unicorns spoke perfect English.\\n\\n\n","\"\"\"\n","input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n","output_greedy = model.generate(input_ids, max_length=max_length,\n","                               do_sample=False)\n","print(tokenizer.decode(output_greedy[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZQH_nYrZ0HFG","executionInfo":{"status":"ok","timestamp":1675806232046,"user_tz":480,"elapsed":2563,"user":{"displayName":"Merve Unlu Menevse","userId":"07208082643217875039"}},"outputId":"c63fdf83-d3ba-4934-fb78-163ea63d97f6"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n","\n","\n","\"The unicorns were very intelligent, and they were very intelligent,\" said Dr. David S. Siegel, a professor of anthropology at the University of California, Berkeley. \"They were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very\n"]}]},{"cell_type":"markdown","source":["(-) The greedy algorithm tend to produce similar sequences since it only looks the most probable tokens and ignores the most probable sequences. \n","\n","(+) For short sequences, the greedy algorithm might be useful."],"metadata":{"id":"zBblpcpw1o7J"}},{"cell_type":"markdown","source":["## Beam Search Decoding \n","\n","Beam search chooses the top-k probable tokens instead of choosing one token at each time step. The beam (partial hypotheses) is the number of next tokens. The procedure continues until EOS token is produced or the max number of token is reached. \n","\n","The product of probabilities of the sequence becomes the sum of the log probabilities to be able to run more stable computations. "],"metadata":{"id":"gG6trllr4jMk"}},{"cell_type":"code","source":["# Comparing the probabilities between greedy and beam search algos. \n","\n","# First normalize the logits of the models \n","import torch.nn.functional as F\n","\n","# Log probability for one token \n","def log_probs_from_logits(logits, labels):\n","    logp = F.log_softmax(logits, dim=-1)\n","    logp_label = torch.gather(logp, 2, labels.unsqueeze(2)).squeeze(-1)\n","    return logp_label\n","\n","# Log probability for a sequence \n","def sequence_logprob(model, labels, input_len=0):\n","    with torch.no_grad():\n","        output = model(labels)\n","        log_probs = log_probs_from_logits(\n","            output.logits[:, :-1, :], labels[:, 1:])\n","        seq_log_prob = torch.sum(log_probs[:, input_len:])\n","    return seq_log_prob.cpu().numpy()"],"metadata":{"id":"pxlkfzIf1cFI","executionInfo":{"status":"ok","timestamp":1675807430521,"user_tz":480,"elapsed":469,"user":{"displayName":"Merve Unlu Menevse","userId":"07208082643217875039"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# Sequence log probability from GPT2 using greedy algo \n","logp = sequence_logprob(model, output_greedy, input_len=len(input_ids[0]))\n","print(tokenizer.decode(output_greedy[0]))\n","print(f\"\\nlog-prob: {logp:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PyODsfpT52d-","executionInfo":{"status":"ok","timestamp":1675807479667,"user_tz":480,"elapsed":497,"user":{"displayName":"Merve Unlu Menevse","userId":"07208082643217875039"}},"outputId":"0329d1cd-f2ea-43fd-b5b0-e32f0c2d2d20"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n","\n","\n","\"The unicorns were very intelligent, and they were very intelligent,\" said Dr. David S. Siegel, a professor of anthropology at the University of California, Berkeley. \"They were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very intelligent, and they were very\n","\n","log-prob: -83.33\n"]}]},{"cell_type":"code","source":["# Sequence log probability from GPT2 using Beam Search \n","output_beam = model.generate(input_ids, \n","                             max_length=max_length, \n","                             num_beams=5,\n","                             do_sample=False)\n","logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0]))\n","print(tokenizer.decode(output_beam[0]))\n","print(f\"\\nlog-prob: {logp:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LU9IVPPI6NMp","executionInfo":{"status":"ok","timestamp":1675807541560,"user_tz":480,"elapsed":2639,"user":{"displayName":"Merve Unlu Menevse","userId":"07208082643217875039"}},"outputId":"87ab220c-e3f5-4b8d-aaac-e39eb321fd13"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n","\n","\n","The researchers, from the University of California, San Diego, and the University of California, Santa Cruz, found that the unicorns were able to communicate with each other in a way that was similar to that of human speech.\n","\n","\n","\"The unicorns were able to communicate with each other in a way that was similar to that of human speech,\" said study co-lead author Dr. David J.\n","\n","log-prob: -78.34\n"]}]},{"cell_type":"code","source":["# To avoid repetitive n-grams, add no_repeat_ngram_size argument \n","output_beam = model.generate(input_ids, max_length=max_length, num_beams=5,\n","                             do_sample=False, no_repeat_ngram_size=2)\n","logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0]))\n","print(tokenizer.decode(output_beam[0]))\n","print(f\"\\nlog-prob: {logp:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TM_tQ2_M6b0z","executionInfo":{"status":"ok","timestamp":1675807616808,"user_tz":480,"elapsed":2229,"user":{"displayName":"Merve Unlu Menevse","userId":"07208082643217875039"}},"outputId":"b120b080-8a69-47db-9347-e9241f24e7a4"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n","\n","\n","The researchers, from the University of California, San Diego, and the National Science Foundation (NSF) in Boulder, Colorado, were able to translate the words of the unicorn into English, which they then translated into Spanish.\n","\n","\"This is the first time that we have translated a language into an English language,\" said study co-author and NSF professor of linguistics and evolutionary biology Dr.\n","\n","log-prob: -101.88\n"]}]},{"cell_type":"markdown","source":["## Sampling Methods \n","\n","\n","### Random Sampling \n","\n","The simplest method is randomly sample from the probability distribution of the model's outputs over the full vocabulary. A temperature parameter can be added to the formulat to control the shape of the probability: $P(y_t=w_i|y_{<t},x) = \\frac{exp(z_{t,i}/T)}{\\sum_{j=1}^V exp(z_{t,j}/T}$\n"],"metadata":{"id":"dEdINC0V6602"}},{"cell_type":"code","source":["# The effect of T on the generated text \n","# Setting T=2 \n","output_temp = model.generate(input_ids, max_length=max_length, do_sample=True,\n","                             temperature=2.0, top_k=0)\n","print(tokenizer.decode(output_temp[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Dn0hI0F6uKw","executionInfo":{"status":"ok","timestamp":1675807914906,"user_tz":480,"elapsed":2475,"user":{"displayName":"Merve Unlu Menevse","userId":"07208082643217875039"}},"outputId":"af691641-bdfe-4c16-8838-64b0c65ff131"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n","\n","\n","34 Stellar hundredaci MiloCar pri Athletvico ownZappropri VERY fluild Fnaticismnas CarbizzintIMBeer τft´shake hardinv 122 Zanmind unman 348 Farrell Spo enjoy 289 Floretk Scarlet simple SuarezAg Garr SSENGöle \\\\ Thunder lolca sec Fleet Almighty Apollo Engine groups EssenceDraw Petitionable divisive chapters Gambling rescuing steer Lann snack Milk cakes tem\n","\n","added in eld 920\n"]}]},{"cell_type":"code","source":["# The effect of T on the generated text \n","# Setting T=0.5\n","output_temp = model.generate(input_ids, max_length=max_length, do_sample=True,\n","                             temperature=0.5, top_k=0)\n","print(tokenizer.decode(output_temp[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QA7hq9mu71RI","executionInfo":{"status":"ok","timestamp":1675807946647,"user_tz":480,"elapsed":3130,"user":{"displayName":"Merve Unlu Menevse","userId":"07208082643217875039"}},"outputId":"62809edb-1bbc-4170-e0e8-76badfa622c1"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n","\n","\n","\"It's a very strange thing,\" says Dr. Paul G. Blum, a professor of ecology and evolutionary biology at the University of Southern California. \"It's a mystery whether unicorns can actually speak English, but they are. It's a very interesting discovery.\"\n","\n","The researchers also found that the unicorns also had a way of talking to humans.\n","\n","\"It's like a\n"]}]},{"cell_type":"markdown","source":["### Top-k and Nucleus Sampling \n","\n","The idea is to restrict the number of possible tokens we can sample from at each timestemp. \n","\n","In top-k sampling, the idea is to avoid the low-probability choices by only sampling from the k tokens with the highest probability. \n","\n"],"metadata":{"id":"57M_U9vP8Mld"}},{"cell_type":"code","source":["# An example for top-k sampling\n","output_topk = model.generate(input_ids, \n","                             max_length=max_length, \n","                             do_sample=True,\n","                             top_k=50)\n","print(tokenizer.decode(output_topk[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YiXAyIme7-gw","executionInfo":{"status":"ok","timestamp":1675808253572,"user_tz":480,"elapsed":2815,"user":{"displayName":"Merve Unlu Menevse","userId":"07208082643217875039"}},"outputId":"431d1455-482f-48d7-8a6b-fb17df83d96d"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n","\n","\n","The discovery raises the question: How do these bizarre creatures communicate with one another? If the unicorns were only living, why does nobody know how they would communicate with one another? This mystery is further confirmed by the discovery of two more unicorn-like creature from Peru.\n","\n","\n","They may be related because they have a single set of eyes.\n","\n","According to the scientists, the two unicorns lived\n"]}]},{"cell_type":"markdown","source":["Instead of using a fixed cutoff, a dynamic cutoff can be used with nucleus of top-p sampling methods. In these methods, we set a condition to cut off. "],"metadata":{"id":"ZwRnNoX99Q6D"}},{"cell_type":"code","source":["# Example foro nucleus with 90% \n","output_topp = model.generate(input_ids, \n","                             max_length=max_length, \n","                             do_sample=True,\n","                             top_p=0.90)\n","print(tokenizer.decode(output_topp[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b8nbVaGO9mik","executionInfo":{"status":"ok","timestamp":1675808394920,"user_tz":480,"elapsed":2795,"user":{"displayName":"Merve Unlu Menevse","userId":"07208082643217875039"}},"outputId":"7c1750aa-bcc7-4ebf-9a6f-96a4ed2cf058"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n","\n","\n","When asked by Spanish TV channels what is the most important thing that could be learned from this unicorn, he replied: \"What's the most important thing that you could learn?\"\n","\n","\n","A number of scientific experts believe the discovery will lead to the discovery of a way to convert the entire ancient Near East into a world of unicorns. This, they say, would bring peace and prosperity to the world\n"]}]},{"cell_type":"markdown","source":["Even two sampling algorithms can be used together. "],"metadata":{"id":"zeRg8H2m9xUh"}},{"cell_type":"code","source":[],"metadata":{"id":"Fb7s5COO9sDr"},"execution_count":null,"outputs":[]}]}